{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1698745944996,
     "user": {
      "displayName": "Mahsa",
      "userId": "00726938084428611696"
     },
     "user_tz": -210
    },
    "id": "o2CNQkqhIHqX"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class node:\n",
    "  def __init__(self ,parent, left, right , values , column, threshhold):\n",
    "    self.parent:node = parent\n",
    "    self.left:node  = left\n",
    "    self.right:node = right\n",
    "    self.values:np.ndarray = values\n",
    "    self.column:int = column\n",
    "    self.threshhold:float = threshhold\n",
    "\n",
    "  def is_leaf(self):\n",
    "    if self.values is None:\n",
    "      return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "executionInfo": {
     "elapsed": 872,
     "status": "ok",
     "timestamp": 1698745952251,
     "user": {
      "displayName": "Mahsa",
      "userId": "00726938084428611696"
     },
     "user_tz": -210
    },
    "id": "6ZRoK_wVGsVx"
   },
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    # Multiclass Decision Tree classifier\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=5, n_features=None ):\n",
    "        \"\"\"\n",
    "        Initialize the Decision Tree model.\n",
    "        \"\"\"\n",
    "        #my code\n",
    "        self.n_features = n_features\n",
    "        self.max_depth=max_depth\n",
    "        self.min_samples_split=min_samples_split\n",
    "        #\n",
    "        self.tree = node(None, None, None, None, None, None) # self.root=None\n",
    "        self.number_of_classes = -1\n",
    "        self.classes = None\n",
    "\n",
    "    def fit(self, X, Y, max_depth=5, kind='best', sample_size=20):\n",
    "      #To DO\n",
    "        \"\"\"\n",
    "        Fit the Decision Tree model to the provided data.\n",
    "\n",
    "        Args:\n",
    "        - X: Input features.\n",
    "        - Y: Labels.\n",
    "        - max_depth: Maximum depth of the decision tree.\n",
    "        - kind: 'best' for best split(check all the possible splits),\n",
    "         'random' for random split(check sample_size candidates for the splits on each column).\n",
    "        - sample_size: Number of random samples to consider for splitting (for 'random' kind).\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "\n",
    "        Example:\n",
    "        >>> tree = DecisionTree()\n",
    "        >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n",
    "        >>> Y = np.array([0, 1, 2])\n",
    "        >>> tree.fit(X, Y, max_depth=5, kind='best', sample_size=20)\n",
    "        \"\"\"\n",
    "        #my code\n",
    "        self.n_features=X.shape[1]\n",
    "        #\n",
    "        self.classes = np.unique(Y)\n",
    "        self.number_of_classes = len(self.classes)\n",
    "        self.tree = self._tree_builder(self.tree, X, Y, max_depth, kind=kind, sample_size=sample_size)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "      #To DO\n",
    "        \"\"\"\n",
    "        Predict class labels for input data.\n",
    "\n",
    "        Args:\n",
    "        - X: Input features for prediction.\n",
    "\n",
    "        Returns:\n",
    "        - Predicted class labels.\n",
    "\n",
    "        Example:\n",
    "        >>> tree = DecisionTree()\n",
    "        >>> X = np.array([[2, 3], [3, 4]])\n",
    "        >>> predicted_labels = tree.predict(X)\n",
    "        \"\"\"\n",
    "        predicted_labels = []\n",
    "        for x in X:\n",
    "            label = self._predict_tree(self.tree, x)\n",
    "            predicted_labels.append(label)\n",
    "        return np.array(predicted_labels)\n",
    "\n",
    "    def _predict_tree(self, tree, X):\n",
    "      #To DO\n",
    "        \"\"\"\n",
    "        Predict class labels for input data using the decision tree.\n",
    "        This function can be used recursively to buid the predictions.\n",
    "\n",
    "        Args:\n",
    "        - tree: Current decision tree node.\n",
    "        - X: Input data for prediction.\n",
    "\n",
    "        Returns:\n",
    "        - Predicted class labels.\n",
    "\n",
    "        Example:\n",
    "        >>> tree = DecisionTree()\n",
    "        >>> node = tree.tree\n",
    "        >>> X = np.array([[2, 3], [3, 4]])\n",
    "        >>> predicted_labels = tree._predict_tree(node, X)\n",
    "        \"\"\"\n",
    "        #my code\n",
    "\n",
    "        #\n",
    "        if tree.is_leaf():\n",
    "            return np.argmax(tree.values)\n",
    "        if X[tree.column] <= tree.threshold:\n",
    "            return self._predict_tree(tree.left, X)\n",
    "        else:\n",
    "            return self._predict_tree(tree.right, X)\n",
    "\n",
    "    def _tree_builder(self, tree, X, Y, depth, kind, sample_size):\n",
    "      #To DO\n",
    "        \"\"\"\n",
    "        Build the Decision Tree recursively.\n",
    "\n",
    "        Args:\n",
    "        - tree: Current decision tree node.\n",
    "        - X: Input features for the current node.\n",
    "        - Y: Labels for the current node.\n",
    "        - depth: Current depth in the tree.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "\n",
    "        Example:\n",
    "        >>> tree = DecisionTree()\n",
    "        >>> node = tree.tree\n",
    "        >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n",
    "        >>> Y = np.array([0, 1, 0])\n",
    "        >>> tree._tree_builder(node, X, Y, depth=1)\n",
    "        \"\"\"\n",
    "        if depth == 0 or len(np.unique(Y)) == 1:\n",
    "            self._build_leaf(tree, Y)\n",
    "        else:\n",
    "            if kind == 'best':\n",
    "                best_column, best_threshold = self._find_split(X, Y)\n",
    "            elif kind == 'random':\n",
    "                best_column, best_threshold = self._find_random_split(X, Y, sample_size)\n",
    "            left_indices = X[:, best_column] <= best_threshold\n",
    "            right_indices = X[:, best_column] > best_threshold\n",
    "            left_node = node(tree, None, None, None, None, None)\n",
    "            right_node = node(tree, None, None, None, None, None)\n",
    "            tree.column = best_column\n",
    "            tree.threshold = best_threshold\n",
    "            tree.left = left_node\n",
    "            tree.right = right_node\n",
    "            self._tree_builder(left_node, X[left_indices], Y[left_indices], depth - 1, kind=kind, sample_size=sample_size)\n",
    "            self._tree_builder(right_node, X[right_indices], Y[right_indices], depth - 1, kind=kind, sample_size=sample_size)\n",
    "\n",
    "\n",
    "    def _check_leaf(self, Y):\n",
    "        # is_leaf = self.tree.is_leaf(Y)\n",
    "        # return is_leaf\n",
    "        return len(np.unique(Y)) == 1\n",
    "\n",
    "    def _build_leaf(self, node, Y):\n",
    "      #To DO\n",
    "        \"\"\"\n",
    "        Build a leaf node and assign class probabilities to node.values\n",
    "        according to Y values in this node.\n",
    "        The values must be an np.ndarray which the first index is\n",
    "        the probability of the sample in this node to belong to\n",
    "        class with label=self.classes[0] and so on for other indexes.\n",
    "\n",
    "        Args:\n",
    "        - node: Current decision tree node which is going to be a leaf.\n",
    "        - Y: Labels for the current node.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "\n",
    "        Example:\n",
    "        >>> tree = DecisionTree()\n",
    "        >>> node = tree.tree\n",
    "        >>> Y = np.array([0, 1, 0])\n",
    "        >>> tree._build_leaf(node, Y)\n",
    "        \"\"\"\n",
    "        node.values = np.zeros(self.number_of_classes)\n",
    "        for y in Y:\n",
    "            node.values[y] += 1\n",
    "        node.values /= len(Y)\n",
    "\n",
    "    def _calculate_entropy(self, labels):\n",
    "      #To DO\n",
    "        \"\"\"\n",
    "        Calculate the entropy of a set of labels.\n",
    "\n",
    "        Args:\n",
    "        - labels: Input labels.\n",
    "\n",
    "        Returns:\n",
    "        - Entropy value.\n",
    "\n",
    "        Example:\n",
    "        >>> tree = DecisionTree()\n",
    "        >>> labels = np.array([0, 1, 0, 1, 1])\n",
    "        >>> entropy = tree._calculate_entropy(labels)\n",
    "        \"\"\"\n",
    "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "        probabilities = counts / len(labels)\n",
    "        entropy = -np.sum(probabilities * np.log2(probabilities))\n",
    "        return entropy\n",
    "\n",
    "    def _information_gain(self, X, Y, column, threshold):\n",
    "      #To DO\n",
    "        \"\"\"\n",
    "        Calculate information gain for a potential split.\n",
    "\n",
    "        Args:\n",
    "        - X: Input features for the split.\n",
    "        - Y: Labels for the split.\n",
    "        - column: Column index for the split.\n",
    "        - row: row index for the split.\n",
    "\n",
    "        Returns:\n",
    "        - Information gain value.\n",
    "\n",
    "        Example:\n",
    "        >>> tree = DecisionTree()\n",
    "        >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n",
    "        >>> Y = np.array([0, 1, 0])\n",
    "        >>> gain = tree._information_gain(X, Y, column=1, threshold=2)\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        total_entropy = self._calculate_entropy(Y)\n",
    "        left_indices = X[:, column] <= threshold\n",
    "        right_indices = X[:, column] > threshold\n",
    "        left_entropy = self._calculate_entropy(Y[left_indices])\n",
    "        right_entropy = self._calculate_entropy(Y[right_indices])\n",
    "        weighted_entropy = (len(Y[left_indices]) / len(Y)) * left_entropy + (len(Y[right_indices]) / len(Y)) * right_entropy\n",
    "        information_gain = total_entropy - weighted_entropy\n",
    "        return information_gain\n",
    "\n",
    "    def _find_split(self, X, Y):\n",
    "      #To DO\n",
    "        \"\"\"\n",
    "        Find the best or best random split for the decision tree.\n",
    "        Remember that there are two versions of this function according to the\n",
    "        'kind' and 'sample_size' arguments that are provided to the constructor.\n",
    "        The random samples must be in the range of the values in the dataset and\n",
    "        they must be unique. The sample_size is an upper bound, as\n",
    "        the unique values might be less than sample_size.\n",
    "\n",
    "\n",
    "        Args:\n",
    "        - X: Input features for the split.\n",
    "        - Y: Labels for the split.\n",
    "\n",
    "        Returns:\n",
    "        - Tuple (best_row, best_column) representing the chosen split.\n",
    "\n",
    "        Example:\n",
    "        >>> tree = DecisionTree()\n",
    "        >>> X = np.array([[1, 2], [2, 3], [3, 4]])\n",
    "        >>> Y = np.array([0, 1, 0])\n",
    "        >>> split = tree._find_split(X, Y)\n",
    "        \"\"\"\n",
    "        best_information_gain = 0\n",
    "        best_column = 0\n",
    "        best_threshold = 0\n",
    "        for column in range(X.shape[1]):\n",
    "            unique_values = np.unique(X[:, column])\n",
    "            for threshold in unique_values:\n",
    "                information_gain = self._information_gain(X, Y, column, threshold)\n",
    "                if information_gain > best_information_gain:\n",
    "                    best_information_gain = information_gain\n",
    "                    best_column = column\n",
    "                    best_threshold = threshold\n",
    "        return best_column, best_threshold\n",
    "\n",
    "\n",
    "    def _find_random_split(self, X, Y, sample_size):\n",
    "        best_information_gain = 0\n",
    "        best_column = 0\n",
    "        best_threshold = 0\n",
    "        for _ in range(sample_size):\n",
    "            column = np.random.randint(0, X.shape[1])\n",
    "            threshold = np.random.choice(np.unique(X[:, column]))\n",
    "            information_gain = self._information_gain(X, Y, column, threshold)\n",
    "            if information_gain > best_information_gain:\n",
    "                best_information_gain = information_gain\n",
    "                best_column = column\n",
    "                best_threshold = threshold\n",
    "        return best_column, best_threshold\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "executionInfo": {
     "elapsed": 1395,
     "status": "error",
     "timestamp": 1698745957569,
     "user": {
      "displayName": "Mahsa",
      "userId": "00726938084428611696"
     },
     "user_tz": -210
    },
    "id": "v_2_KcQOIFyT",
    "outputId": "9a6d762d-34cd-4958-f522-104baddb9d13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.28087808  1.40445145 -0.99437421 ... -1.36477942 -1.37765935\n",
      "   1.00076637]\n",
      " [ 0.53550748  0.61497875  0.04821114 ... -1.09934053  0.18752709\n",
      "  -0.25752972]\n",
      " [-0.86842676  0.26010107  1.05977427 ...  0.4643568  -0.50460435\n",
      "   0.48626646]\n",
      " ...\n",
      " [-0.76477821 -1.45608311  1.01865437 ... -0.02316979 -0.44090869\n",
      "  -1.53729138]\n",
      " [-0.28829529 -0.57045743 -1.05593108 ...  1.008429    1.38152953\n",
      "   0.02168242]\n",
      " [ 1.54301713  1.34746804 -1.06544863 ...  0.41867174 -3.51290644\n",
      "   0.10420939]]\n"
     ]
    }
   ],
   "source": [
    "# Load the .npy file\n",
    "x = np.load('x.npy')\n",
    "\n",
    "# Display the data\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "executionInfo": {
     "elapsed": 435,
     "status": "error",
     "timestamp": 1698746043876,
     "user": {
      "displayName": "Mahsa",
      "userId": "00726938084428611696"
     },
     "user_tz": -210
    },
    "id": "tGhO9lKC1wjS",
    "outputId": "e967a34a-85f8-4d8b-81bd-5508e33171dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 3 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Lets read output labels\n",
    "y = np.load('y.npy')\n",
    "\n",
    "# Display outputs\n",
    "print(y)\n",
    "classes= np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 522,
     "status": "ok",
     "timestamp": 1698691798550,
     "user": {
      "displayName": "rasa bakhtiary",
      "userId": "17280514432487963804"
     },
     "user_tz": -210
    },
    "id": "-FUFwDW52xnR",
    "outputId": "e94fe4ed-7e9b-4267-ba9a-684363ed829d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=len(x[1])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "lRMAJG1710v8"
   },
   "outputs": [],
   "source": [
    "tree = DecisionTree(min_samples_split=2, max_depth=8, n_features=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "error",
     "timestamp": 1698745931171,
     "user": {
      "displayName": "Mahsa",
      "userId": "00726938084428611696"
     },
     "user_tz": -210
    },
    "id": "cq7H0ttn4Tm1",
    "outputId": "3dd7538f-30ac-460b-eaf8-de664ef9f1d9"
   },
   "outputs": [],
   "source": [
    "X=np.array(x)\n",
    "Y=np.array(y)\n",
    "tree.fit(X, Y, max_depth=5, kind='best', sample_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 40)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 3, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
